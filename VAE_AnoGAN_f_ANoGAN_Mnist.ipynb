{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_AnoGAN_f-ANoGAN_Mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AissatouPaye/AnomalyDetection.jl/blob/master/VAE_AnoGAN_f_ANoGAN_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD1LeaxhbcKz",
        "colab_type": "text"
      },
      "source": [
        "## VAE , AnoGAN and F-AnoGAN\n",
        "\n",
        "\n",
        "Use the MNIST Dataset to see how VAE, AnoGAN and F-AnoGAN works as Anomalies detector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Win_CcWUZ4Ka",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f1ec6b15-150a-4dfb-9034-f94760ce59dd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_mP-6DqaLnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "### use MNIST dataset for the GAN models\n",
        "\n",
        "from keras .datasets import mnist \n",
        "\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Input, Reshape, Dense, Dropout, MaxPooling2D, Conv2D, Flatten\n",
        "from keras.layers import Conv2DTranspose, LeakyReLU\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "from keras.utils. generic_utils import Progbar\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "from typing import Tuple\n",
        "from keras.models import load_model\n",
        "from keras import backend as K\n",
        "from sklearn.manifold import TSNE\n",
        "from keras.layers import concatenate\n",
        "\n",
        "# Google Colab\n",
        "from google.colab import drive\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "import copy\n",
        "from enum import Enum\n",
        "\n",
        "from keras.callbacks import TensorBoard\n",
        "import io\n",
        "from PIL import Image\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from math import floor\n",
        "from skimage.transform import resize\n",
        "from scipy.linalg import sqrtm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5CfXcqLdkU2",
        "colab_type": "text"
      },
      "source": [
        "MNIST DATASET\n",
        "\n",
        "Download the data and create a traning and test loader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFIs7HM3ddzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9f2d265d-9348-4a97-b9fb-15bda101b7ae"
      },
      "source": [
        "# Train and test data\n",
        "\n",
        "(X_train,Y_train),(X_test,Y_test)=mnist.load_data()\n",
        "### Convert image scale to -1 to 1 ####\n",
        "\n",
        "X_train=(X_train.astype(np.float32)- DataParm.image_size_127_5.value)/DataParm.image_size_127_5.value\n",
        "X_test=(X_test.astype(np.float32)- DataParm.image_size_127_5.value)/DataParm.image_size_127_5.value\n",
        "\n",
        "#### Convert to batch size, width, height, channel ####\n",
        "X_train=X_train[:,:,:,None]\n",
        "X_test=X_test[:,:,:,None]\n",
        "\n",
        "#Learn only image with labe 1 ( our positif sample that the generative model have to learn)\n",
        "\n",
        "X_train=X_train[Y_train==1]\n",
        "X_test=X_test[Y_test==1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18SYYc7Bb5sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####Setting the general parameter that will be use to save the models results ###\n",
        "\n",
        "class DataParm(Enum):\n",
        "    # VAE Path to save  models, images, and Tensorboard logs\n",
        "    common_path_VAE = '/content/drive/My Drive/AnoDetect_implementation/VAE'\n",
        "    ##### Path AnoGAN\n",
        "    common_path = '/content/drive/My Drive/AnoDetect_implementation/AnoGAN'\n",
        "    # EfficentAnnoGAN: Path to store the model, images, and Tensorboard logs\n",
        "    common_path_efficient = '/ content / drive / My Drive /GAN/f-AnoGAN/'\n",
        "    image_size_127_5 = 127.5\n",
        "    image_size= X_train.shape[1]\n",
        "    original_dim = image_size*image_size\n",
        "    input_shape= (image_size,image_size,1)\n",
        "    batch_size_64 = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECODumiMd7zJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3996a85f-9562-4907-bdce-59807651fe7f"
      },
      "source": [
        "X_train[0].shape\n",
        "\n",
        "\n",
        "### visualize one sample of the data : showing a 1 of the training set ####\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8Gguf3HhbVX",
        "colab_type": "text"
      },
      "source": [
        "### VAE \n",
        "The VAE has a modular design. The encoder, decoder and VAE\n",
        "are 3 models that share weights. After training the VAE model,\n",
        "the encoder can be used to generate latent vectors.\n",
        "The decoder can be used to generate MNIST digits by sampling the\n",
        "latent vector from a Gaussian distribution with mean = 0 and std = 1.\n",
        "### Reference\n",
        "[1] Kingma, Diederik P., and Max Welling.\n",
        "\"Auto-Encoding Variational Bayes.\"\n",
        "https://arxiv.org/abs/1312.6114\n",
        "\n",
        "\n",
        "#####  put the GENERAL ARCHITECTURE  here#####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxMOwBTkZvHl",
        "colab_type": "text"
      },
      "source": [
        "ENCODER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc_n58Jobg8Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### Convolution VAE : layer of encoder and decoder are convolution net #####\n",
        "\n",
        "####Building the encoder  ######\n",
        "\n",
        "class EncoderParm(Enum):\n",
        "      conv2d_filter_64 = 64\n",
        "      conv2d_kernel_5_5 = (5, 5)\n",
        "      conv2d_stride_2_2 = (2, 2)\n",
        "      conv2d_padding_same = 'same'\n",
        "\n",
        "      leaky_reLU_param_0_2 = 0.2\n",
        "\n",
        "      conv2d_second_filter_128 = 128\n",
        "      conv2d_second_kernel_5_5 = (5, 5)\n",
        "      conv2d_second_stride_2_2 = (2, 2)\n",
        "      conv2d_second_padding_same = 'same'\n",
        "      \n",
        "      dense_1=1\n",
        "      out_activation='relu'\n",
        "    \n",
        "def  Encoder_model():\n",
        "  \"\"\"\n",
        "  Two layers convolution network\n",
        "  \n",
        "  Model that output a mean and variance \n",
        "  \"\"\"\n",
        "  input = Input(shape=EncoderParm.input_shape.value , name='Encoder_X')\n",
        "  ##### convolution layer \n",
        "  conv1= Conv2D(filters=conv2d_filter_64,\n",
        "                 kernel_size=conv2d_kernel_5_5,\n",
        "                stride=conv2d_stride_2_2,\n",
        "                padding='same')(input)\n",
        "  \n",
        "  conv1=LeakyRelu(EncoderParm.leaky_reLU_param_0_2.value)(conv1)\n",
        "  \n",
        "  conv2=Conv2D(filters = conv2d_second_filter_128,\n",
        "               kernel_size = conv2d_second_kernel_5_5,\n",
        "               stride = conv2d_second_stride_2_2,\n",
        "               padding = 'same')(conv1)\n",
        "  \n",
        "  conv2=LeakyRelu(EncoderParm.leaky_reLU_param_0_2.value)(conv2)\n",
        "  \n",
        "  # shape info needed to build decoder model\n",
        "\n",
        "  shape = K.int_shape(conv2)\n",
        "  \n",
        "  fc=Flatten()(conv2)\n",
        "  fc=Dense(EncoderParm.dense_1.value)(fc)\n",
        "  output=Activation(EncoderParm.out_activation.value)(fc)\n",
        "  \n",
        "  #####\n",
        "  latent_dim=1 ## number of stack layer in the latent space \n",
        "  z_mean  =  Dense ( latent_dim ,  activation = 'linear' ) ( hidden ) \n",
        "  z_sigma  =  Dense ( latent_dim ,  activation = 'linear' ) ( hidden )\n",
        "  \n",
        "  model=Model(inputs=[input],outputs=[output])  \n",
        "  return Model , shape\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##### Sampler  ####\n",
        "\n",
        "class Sampler (self):\n",
        "  \n",
        "  \"\"\"\n",
        "  Use reparametrizatin trick instead od sampling from Q(Z/X), sample from epsilon - N(0,I)\n",
        "  \n",
        "  z = z_mean+ sqrt(z_var)* epsilon\n",
        "  \"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_Xl0OprbliY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}